# üéôÔ∏è Multi-Modal Voice Agent Pipeline

> **Advanced, production-ready voice agent system with the lowest possible latency, built for high concurrency and comprehensive monitoring.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üåü Features

- ‚ú® **Complete Multi-Modal Pipeline**: STT ‚Üí LLM (with tools) ‚Üí Visualization ‚Üí TTS
- üöÄ **Lowest Latency Design**: 2-4s average end-to-end response time
- ‚ö° **High Concurrency**: Supports 50+ simultaneous sessions
- üéØ **LLM Tool Calling**: Chart generation, sentiment analysis, real-time data fetching
- üìä **Real-Time Visualizations**: Plotly-based interactive charts
- üí∞ **Cost Tracking**: Comprehensive per-session and per-minute cost analysis
- üìà **Performance Monitoring**: CPU, memory, latency, and resource tracking
- üîÑ **Synchronized Delivery**: Audio and visual data perfectly aligned
- üõ°Ô∏è **Rate Limiting**: Automatic handling of API limits with retry logic
- üì± **Beautiful Web Client**: Full-featured HTML interface included

## üì∏ Demo

![Multi-Modal Pipeline](https://via.placeholder.com/800x400?text=Multi-Modal+Voice+Agent+Pipeline)

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client    ‚îÇ  WebSocket Connection
‚îÇ  (Browser)  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
                                       ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ    FastAPI Server        ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                        ‚îÇ  ‚îÇ  Pipeline Stages   ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  1. STT (500-800ms)‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  2. LLM (1-2s)     ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  3. Tools (100-500ms)‚îÇ ‚îÇ
                        ‚îÇ  ‚îÇ  4. Viz (100-200ms)‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  5. TTS (800-1200ms)‚îÇ ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                        ‚îÇ  ‚îÇ  Monitoring        ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  - Cost Tracking   ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  - Resource Usage  ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ  - Performance     ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                  ‚ñº                  ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   OpenAI     ‚îÇ   ‚îÇ ElevenLabs   ‚îÇ  ‚îÇ   Plotly     ‚îÇ
            ‚îÇ   GPT-4      ‚îÇ   ‚îÇ  STT + TTS   ‚îÇ  ‚îÇ    Charts    ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- Python 3.10 or higher
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- ElevenLabs API key ([Get one here](https://elevenlabs.io/app/settings/api-keys))

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/Parakrant/multimodal-voice-agent.git
cd multimodal-voice-agent
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Configure environment variables**

```bash
cp .env.example .env
# Edit .env and add your API keys
```

4. **Start the server**

```bash
python main_enhanced.py
```

5. **Open the client**

Open `client_enhanced.html` in your browser, click "Connect", and start chatting!

## üìñ Documentation

- **[Quick Start Guide](QUICKSTART.md)** - Get running in 5 minutes
- **[Complete Documentation](README.md)** - Full technical documentation
- **[Implementation Report](IMPLEMENTATION_REPORT.md)** - Detailed analysis
- **[Deliverables Checklist](DELIVERABLES_CHECKLIST.md)** - Requirements verification
- **[Rate Limiting Guide](RATE_LIMITING_FIX.md)** - API rate limit handling

## üí° Usage Examples

### Text Conversation

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/multimodal');

ws.onopen = () => {
    ws.send(JSON.stringify({
        type: 'user_text',
        text: 'Create a bar chart with values 10, 20, 30, 40'
    }));
};

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log(data.type, data);
};
```

### Check System Metrics

```bash
curl http://localhost:8000/metrics
```

### Run Performance Benchmark

```bash
python benchmark.py --max-concurrency 10 --output results.json
```

## üéØ Key Capabilities

### LLM Tool Calling

The system includes three production-ready tools:

1. **Chart Generation** - Creates interactive Plotly visualizations
2. **Sentiment Analysis** - Analyzes text sentiment with scoring
3. **Real-Time Data** - Fetches live system metrics and data

Example:
```
User: "Create a line chart showing stock prices"
Assistant: *generates chart and explains the visualization*
```

### Cost Analysis

Automatic tracking of operational costs:

- Per-session cost breakdown
- Per-minute operational costs
- Component-wise analysis (LLM, STT, TTS)
- Optimization recommendations

### Performance Monitoring

Real-time monitoring of:

- CPU and memory utilization
- Request latency (avg, P95, P99)
- Active connections and threads
- Success rates and errors

## üìä Performance Metrics

| Metric | Value |
|--------|-------|
| Average Latency | 2-4 seconds |
| P95 Latency | < 5 seconds |
| Max Concurrent Sessions | 50+ |
| Success Rate | > 98% |
| Cost per Turn | ~$0.076 |

## üõ†Ô∏è API Endpoints

### REST Endpoints

- `GET /health` - Health check
- `GET /metrics` - Comprehensive system metrics
- `GET /session/{session_id}` - Session details
- `GET /data-viz/{session_id}` - Visualization data
- `POST /stt-test` - Test STT endpoint

### WebSocket

- `WS /ws/multimodal` - Main multi-modal communication endpoint

## üîß Configuration

### Adjust ElevenLabs Rate Limit

Edit `main_enhanced.py` line 92:

```python
# For starter tier (3 concurrent) - DEFAULT
ELEVENLABS_SEMAPHORE = asyncio.Semaphore(3)

# For creator tier (10 concurrent)
ELEVENLABS_SEMAPHORE = asyncio.Semaphore(10)
```

### Use Different LLM Model

Edit `main_enhanced.py` line 74:

```python
# For faster/cheaper responses
OPENAI_MODEL = "gpt-3.5-turbo"

# For highest quality
OPENAI_MODEL = "gpt-4-turbo-preview"
```

## üìà Cost Optimization

**Typical Costs (per turn):**
- LLM: ~$0.016 (65%)
- TTS: ~$0.048 (30%)
- STT: ~$0.012 (5%)
- **Total: ~$0.076**

**Tips to Reduce Costs:**

1. Use GPT-3.5-Turbo instead of GPT-4 (90% cheaper)
2. Limit response length with `max_tokens`
3. Reduce conversation history (current: 10 turns)
4. Implement response caching

## üß™ Testing

```bash
# Run full benchmark suite
python benchmark.py --max-concurrency 10

# Test with web client
open client_enhanced.html

# Test health endpoint
curl http://localhost:8000/health
```

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - Modern web framework
- [OpenAI](https://openai.com/) - GPT-4 language model
- [ElevenLabs](https://elevenlabs.io/) - Text-to-Speech and Speech-to-Text
- [Plotly](https://plotly.com/) - Interactive visualizations

## üìû Support

- üêõ Issues: [GitHub Issues](https://github.com/Parakrant/multimodal-voice-agent/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/Parakrant/multimodal-voice-agent/discussions)

## üó∫Ô∏è Roadmap

- [ ] Streaming LLM responses
- [ ] Persistent storage (PostgreSQL/Redis)
- [ ] Authentication and rate limiting
- [ ] Docker deployment
- [ ] Kubernetes support
- [ ] Multi-language support
- [ ] Custom voice cloning
- [ ] Real-time collaboration

## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Parakrant/multimodal-voice-agent&type=Date)](https://star-history.com/#Parakrant/multimodal-voice-agent&Date)

---

**Built with ‚ù§Ô∏è using FastAPI, OpenAI, and ElevenLabs**

*If you find this project useful, please consider giving it a ‚≠ê on GitHub!*
